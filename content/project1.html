---
title: "Project 1: Specific Language Impairment in Children"
author: "Anusha Naeem"
date: '3/15/20'
output:
  pdf_document: default
  html_document: default
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The dataset that I chose for this project was obtained from Kaggle, and contains information about diagnosing specific language impairments in children. Specific language impairment is characterized by a lack of language ability compared to peers, but no obvious physical or mental disability. This dataset compiled information from two different studies, both of which contain results from children trying to complete a wordless picture task. The children were given wordless picture stories and asked to tell the story for a particular picture. I chose this dataset because I’m interesting in potentially becoming a pediatrician in the future, and am really interested in language in general and how it can affect people. This dataset was interesting in helping me investigate how language development can vary in children, and what those differences can mean.</p>
<p>There were a lot of variables in the original dataset, and I ended up splitting the large dataset into two separate ones, and joining them back together after creating a variable called “ID” in Excel. Even still, there were a lot of variables in the original dataset that I didn’t find understandable or useful, so I ended up removing them in Excel before uploading the dataset to RStudio. The variables I kept are defined as follows: -</p>
<ul>
<li>ID = a patient ID for each observation</li>
<li>sex = the gender of the child</li>
<li>age_years = age of the child in years</li>
<li>corpus = the study (one of two) that the observation was taken from</li>
<li>group = designation for the child as either SLI (specific language impairment) or TD (typical development)</li>
<li>child_TNW= total number of words spoken by the child</li>
<li>child_TNS= total number of sentences spoken by the child (it’s noted that higher TNS is more likely for SLI children)</li>
<li>examiner_TNW= total # of words spoken by the examiner (children with SLI are more likely to require support from the examiner)</li>
<li>freqttr = frequency of word types to word token ratio, a measure that divides word types by word tokens and provides a rough measure of lexical diversity</li>
<li>r2iverbs = ratio of raw to inflected verbs (children with SLI often have difficulty with the morphemes -ed, -s, be, and do, which results in the use of raw verbs instead of their inflected forms.)</li>
<li>morwords = number of words in the %mor tier</li>
<li>numpostags = number of different part-of-speech tags</li>
<li>ndos = number of time the word ‘do’ is used</li>
<li>repetition = counts the number of repetitions in a sentece</li>
<li>retracing = number of retracings, defined as when a speaker abandons an utterance but then continues again</li>
<li>fillers = counts the number of fillers used in total</li>
<li>s1gppl= the perplexity of this sample in comparison to a language model trained on all the SLI group for this corpora except the sample</li>
<li>averagesyl = average number of syllables per word</li>
<li>mluwords = mean length of utterance of words</li>
<li>mlumorphemes = mean length of utterance of morphemes (same as above but for sentences instead of words)</li>
<li>mlu100utts= mean length of utterance of 1st 100 words (nly use the first 100 words to calculate MLU)</li>
<li>verbutt = number of utterances consisting of verbs</li>
<li>dss =Developmental Sentence Score, A measure of sentence complexity</li>
<li>ipsyn_total= Index of Productive Syntax Score , another measure of sentence complexity</li>
</ul>
<p>Since this dataset already had a variable (group) defining whether or not the child had been diagnosed with a specific language impairment, I expected to see significant differences in the values of all these different measurements between SLI and TD groups. I also expected to see probably two distinct clusters in my cluster analysis, since I anticipated that the differences in the measures above would lead to two distinct groups of observations in my data.</p>
<pre class="r"><code>lang1 &lt;- read.csv(&quot;lang1.csv&quot;)
lang2 &lt;- read.csv(&quot;lang2.csv&quot;)
library(tidyverse)
library(dplyr)
library(ggplot2)
glimpse(lang1)</code></pre>
<pre><code>## Observations: 1,163
## Variables: 65
## $ ID           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ Y            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
## $ filename     &lt;fct&gt; 413.cha, 420.cha, 427.cha, 444.cha, 474.cha, 475.cha, 47…
## $ sex          &lt;fct&gt; male, male, female, male, female, male, male, male, male…
## $ age          &lt;int&gt; 59, 60, 56, 50, 57, 56, 57, 56, 54, 57, 52, 55, 66, 70, …
## $ age_years    &lt;dbl&gt; 4.916667, 5.000000, 4.666667, 4.166667, 4.750000, 4.6666…
## $ corpus       &lt;fct&gt; ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, EN…
## $ group        &lt;fct&gt; SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, S…
## $ child_TNW    &lt;int&gt; 212, 468, 212, 292, 611, 321, 658, 261, 227, 436, 867, 3…
## $ child_TNS    &lt;int&gt; 66, 67, 67, 90, 100, 64, 97, 62, 58, 70, 130, 62, 106, 1…
## $ examiner_TNW &lt;int&gt; 14, 2, 8, 20, 202, 20, 315, 38, 93, 0, 13, 22, 2, 31, 0,…
## $ freq_ttr     &lt;dbl&gt; 0.412, 0.239, 0.369, 0.232, 0.230, 0.257, 0.197, 0.269, …
## $ r_2_i_verbs  &lt;dbl&gt; 5.1428571, 1.3666667, 0.6000000, 0.6000000, 1.0000000, 0…
## $ mor_words    &lt;int&gt; 194, 385, 195, 259, 539, 284, 458, 245, 216, 400, 712, 2…
## $ num_pos_tags &lt;int&gt; 25, 34, 31, 23, 44, 32, 34, 24, 23, 36, 38, 34, 44, 48, …
## $ n_dos        &lt;int&gt; 0, 1, 3, 1, 1, 0, 1, 0, 0, 0, 8, 1, 4, 7, 3, 0, 1, 0, 0,…
## $ repetition   &lt;int&gt; 7, 47, 13, 16, 21, 13, 109, 1, 3, 5, 46, 23, 41, 13, 230…
## $ retracing    &lt;int&gt; 3, 10, 3, 7, 15, 6, 15, 8, 1, 11, 31, 9, 5, 3, 11, 0, 10…
## $ fillers      &lt;int&gt; 1, 9, 3, 13, 8, 5, 20, 1, 3, 2, 9, 13, 10, 0, 44, 25, 1,…
## $ X            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.1          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.2          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.3          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.4          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.5          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.6          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.7          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.8          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.9          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.10         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.11         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.12         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.13         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.14         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.15         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.16         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.17         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.18         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.19         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.20         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.21         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.22         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.23         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.24         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.25         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.26         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.27         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.28         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.29         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.30         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.31         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.32         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.33         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.34         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.35         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ word_errors  &lt;int&gt; 8, 16, 0, 4, 8, 10, 1, 3, 16, 2, 4, 8, 8, 2, 0, 4, 3, 0,…
## $ X.36         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.37         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.38         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.39         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.40         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.41         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.42         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ X.43         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
## $ total_error  &lt;int&gt; 12, 9, 6, 12, 7, 5, 10, 12, 4, 11, 24, 19, 12, 2, 5, 9, …</code></pre>
<pre class="r"><code>glimpse(lang2)</code></pre>
<pre><code>## Observations: 225
## Variables: 10
## $ ID          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
## $ s_1g_ppl    &lt;dbl&gt; 18.2102, 21.1808, 28.4306, 16.5310, 22.0807, 25.7567, 17.…
## $ total_syl   &lt;int&gt; 248, 545, 233, 436, 536, 290, 761, 239, 275, 457, 1017, 3…
## $ average_syl &lt;dbl&gt; 1.1698113, 1.1645299, 1.0990566, 1.4931507, 0.8772504, 0.…
## $ mlu_words   &lt;dbl&gt; 2.938, 5.839, 2.909, 2.878, 5.674, 4.422, 4.656, 4.070, 3…
## $ verb_utt    &lt;dbl&gt; 0.500, 1.000, 0.851, 0.189, 0.887, 0.953, 0.673, 0.617, 0…
## $ dss         &lt;dbl&gt; 8.41, 6.56, 4.96, 6.20, 9.02, 10.24, 9.80, 12.94, 4.89, 1…
## $ ipsyn_total &lt;int&gt; 45, 77, 56, 58, 94, 55, 67, 41, 46, 79, 86, 60, 80, 99, 7…
## $ word_errors &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, …
## $ total_error &lt;int&gt; 5, 25, 8, 18, 12, 6, 11, 5, 6, 8, 29, 9, 13, 30, 29, 3, 3…</code></pre>
<hr />
</div>
<div id="joining" class="section level2">
<h2>Joining</h2>
<pre class="r"><code>lang1 &lt;- lang1 %&gt;% select(ID, sex, age_years, corpus, group, 
    child_TNW, child_TNS, examiner_TNW, freq_ttr, r_2_i_verbs, 
    mor_words, num_pos_tags, n_dos, repetition, retracing, fillers)

glimpse(lang1)</code></pre>
<pre><code>## Observations: 1,163
## Variables: 16
## $ ID           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ sex          &lt;fct&gt; male, male, female, male, female, male, male, male, male…
## $ age_years    &lt;dbl&gt; 4.916667, 5.000000, 4.666667, 4.166667, 4.750000, 4.6666…
## $ corpus       &lt;fct&gt; ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, EN…
## $ group        &lt;fct&gt; SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, S…
## $ child_TNW    &lt;int&gt; 212, 468, 212, 292, 611, 321, 658, 261, 227, 436, 867, 3…
## $ child_TNS    &lt;int&gt; 66, 67, 67, 90, 100, 64, 97, 62, 58, 70, 130, 62, 106, 1…
## $ examiner_TNW &lt;int&gt; 14, 2, 8, 20, 202, 20, 315, 38, 93, 0, 13, 22, 2, 31, 0,…
## $ freq_ttr     &lt;dbl&gt; 0.412, 0.239, 0.369, 0.232, 0.230, 0.257, 0.197, 0.269, …
## $ r_2_i_verbs  &lt;dbl&gt; 5.1428571, 1.3666667, 0.6000000, 0.6000000, 1.0000000, 0…
## $ mor_words    &lt;int&gt; 194, 385, 195, 259, 539, 284, 458, 245, 216, 400, 712, 2…
## $ num_pos_tags &lt;int&gt; 25, 34, 31, 23, 44, 32, 34, 24, 23, 36, 38, 34, 44, 48, …
## $ n_dos        &lt;int&gt; 0, 1, 3, 1, 1, 0, 1, 0, 0, 0, 8, 1, 4, 7, 3, 0, 1, 0, 0,…
## $ repetition   &lt;int&gt; 7, 47, 13, 16, 21, 13, 109, 1, 3, 5, 46, 23, 41, 13, 230…
## $ retracing    &lt;int&gt; 3, 10, 3, 7, 15, 6, 15, 8, 1, 11, 31, 9, 5, 3, 11, 0, 10…
## $ fillers      &lt;int&gt; 1, 9, 3, 13, 8, 5, 20, 1, 3, 2, 9, 13, 10, 0, 44, 25, 1,…</code></pre>
<pre class="r"><code>glimpse(lang2)</code></pre>
<pre><code>## Observations: 225
## Variables: 10
## $ ID          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
## $ s_1g_ppl    &lt;dbl&gt; 18.2102, 21.1808, 28.4306, 16.5310, 22.0807, 25.7567, 17.…
## $ total_syl   &lt;int&gt; 248, 545, 233, 436, 536, 290, 761, 239, 275, 457, 1017, 3…
## $ average_syl &lt;dbl&gt; 1.1698113, 1.1645299, 1.0990566, 1.4931507, 0.8772504, 0.…
## $ mlu_words   &lt;dbl&gt; 2.938, 5.839, 2.909, 2.878, 5.674, 4.422, 4.656, 4.070, 3…
## $ verb_utt    &lt;dbl&gt; 0.500, 1.000, 0.851, 0.189, 0.887, 0.953, 0.673, 0.617, 0…
## $ dss         &lt;dbl&gt; 8.41, 6.56, 4.96, 6.20, 9.02, 10.24, 9.80, 12.94, 4.89, 1…
## $ ipsyn_total &lt;int&gt; 45, 77, 56, 58, 94, 55, 67, 41, 46, 79, 86, 60, 80, 99, 7…
## $ word_errors &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, …
## $ total_error &lt;int&gt; 5, 25, 8, 18, 12, 6, 11, 5, 6, 8, 29, 9, 13, 30, 29, 3, 3…</code></pre>
<pre class="r"><code>lang1a &lt;- lang1 %&gt;% na.omit()
lang2a &lt;- lang2 %&gt;% na.omit()

glimpse(lang1a)</code></pre>
<pre><code>## Observations: 1,045
## Variables: 16
## $ ID           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ sex          &lt;fct&gt; male, male, female, male, female, male, male, male, male…
## $ age_years    &lt;dbl&gt; 4.916667, 5.000000, 4.666667, 4.166667, 4.750000, 4.6666…
## $ corpus       &lt;fct&gt; ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, EN…
## $ group        &lt;fct&gt; SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, S…
## $ child_TNW    &lt;int&gt; 212, 468, 212, 292, 611, 321, 658, 261, 227, 436, 867, 3…
## $ child_TNS    &lt;int&gt; 66, 67, 67, 90, 100, 64, 97, 62, 58, 70, 130, 62, 106, 1…
## $ examiner_TNW &lt;int&gt; 14, 2, 8, 20, 202, 20, 315, 38, 93, 0, 13, 22, 2, 31, 0,…
## $ freq_ttr     &lt;dbl&gt; 0.412, 0.239, 0.369, 0.232, 0.230, 0.257, 0.197, 0.269, …
## $ r_2_i_verbs  &lt;dbl&gt; 5.1428571, 1.3666667, 0.6000000, 0.6000000, 1.0000000, 0…
## $ mor_words    &lt;int&gt; 194, 385, 195, 259, 539, 284, 458, 245, 216, 400, 712, 2…
## $ num_pos_tags &lt;int&gt; 25, 34, 31, 23, 44, 32, 34, 24, 23, 36, 38, 34, 44, 48, …
## $ n_dos        &lt;int&gt; 0, 1, 3, 1, 1, 0, 1, 0, 0, 0, 8, 1, 4, 7, 3, 0, 1, 0, 0,…
## $ repetition   &lt;int&gt; 7, 47, 13, 16, 21, 13, 109, 1, 3, 5, 46, 23, 41, 13, 230…
## $ retracing    &lt;int&gt; 3, 10, 3, 7, 15, 6, 15, 8, 1, 11, 31, 9, 5, 3, 11, 0, 10…
## $ fillers      &lt;int&gt; 1, 9, 3, 13, 8, 5, 20, 1, 3, 2, 9, 13, 10, 0, 44, 25, 1,…</code></pre>
<pre class="r"><code>glimpse(lang2a)</code></pre>
<pre><code>## Observations: 225
## Variables: 10
## $ ID          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…
## $ s_1g_ppl    &lt;dbl&gt; 18.2102, 21.1808, 28.4306, 16.5310, 22.0807, 25.7567, 17.…
## $ total_syl   &lt;int&gt; 248, 545, 233, 436, 536, 290, 761, 239, 275, 457, 1017, 3…
## $ average_syl &lt;dbl&gt; 1.1698113, 1.1645299, 1.0990566, 1.4931507, 0.8772504, 0.…
## $ mlu_words   &lt;dbl&gt; 2.938, 5.839, 2.909, 2.878, 5.674, 4.422, 4.656, 4.070, 3…
## $ verb_utt    &lt;dbl&gt; 0.500, 1.000, 0.851, 0.189, 0.887, 0.953, 0.673, 0.617, 0…
## $ dss         &lt;dbl&gt; 8.41, 6.56, 4.96, 6.20, 9.02, 10.24, 9.80, 12.94, 4.89, 1…
## $ ipsyn_total &lt;int&gt; 45, 77, 56, 58, 94, 55, 67, 41, 46, 79, 86, 60, 80, 99, 7…
## $ word_errors &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, …
## $ total_error &lt;int&gt; 5, 25, 8, 18, 12, 6, 11, 5, 6, 8, 29, 9, 13, 30, 29, 3, 3…</code></pre>
<pre class="r"><code>joineddata &lt;- lang1a %&gt;% inner_join(lang2a, by = &quot;ID&quot;)
joineddata &lt;- joineddata %&gt;% filter(sex == &quot;male&quot; | sex == &quot;female&quot;)
# had one case where sex wasn&#39;t specified

glimpse(joineddata)</code></pre>
<pre><code>## Observations: 225
## Variables: 25
## $ ID           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ sex          &lt;fct&gt; male, male, female, male, female, male, male, male, male…
## $ age_years    &lt;dbl&gt; 4.916667, 5.000000, 4.666667, 4.166667, 4.750000, 4.6666…
## $ corpus       &lt;fct&gt; ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, ENNI, EN…
## $ group        &lt;fct&gt; SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, SLI, S…
## $ child_TNW    &lt;int&gt; 212, 468, 212, 292, 611, 321, 658, 261, 227, 436, 867, 3…
## $ child_TNS    &lt;int&gt; 66, 67, 67, 90, 100, 64, 97, 62, 58, 70, 130, 62, 106, 1…
## $ examiner_TNW &lt;int&gt; 14, 2, 8, 20, 202, 20, 315, 38, 93, 0, 13, 22, 2, 31, 0,…
## $ freq_ttr     &lt;dbl&gt; 0.412, 0.239, 0.369, 0.232, 0.230, 0.257, 0.197, 0.269, …
## $ r_2_i_verbs  &lt;dbl&gt; 5.1428571, 1.3666667, 0.6000000, 0.6000000, 1.0000000, 0…
## $ mor_words    &lt;int&gt; 194, 385, 195, 259, 539, 284, 458, 245, 216, 400, 712, 2…
## $ num_pos_tags &lt;int&gt; 25, 34, 31, 23, 44, 32, 34, 24, 23, 36, 38, 34, 44, 48, …
## $ n_dos        &lt;int&gt; 0, 1, 3, 1, 1, 0, 1, 0, 0, 0, 8, 1, 4, 7, 3, 0, 1, 0, 0,…
## $ repetition   &lt;int&gt; 7, 47, 13, 16, 21, 13, 109, 1, 3, 5, 46, 23, 41, 13, 230…
## $ retracing    &lt;int&gt; 3, 10, 3, 7, 15, 6, 15, 8, 1, 11, 31, 9, 5, 3, 11, 0, 10…
## $ fillers      &lt;int&gt; 1, 9, 3, 13, 8, 5, 20, 1, 3, 2, 9, 13, 10, 0, 44, 25, 1,…
## $ s_1g_ppl     &lt;dbl&gt; 18.2102, 21.1808, 28.4306, 16.5310, 22.0807, 25.7567, 17…
## $ total_syl    &lt;int&gt; 248, 545, 233, 436, 536, 290, 761, 239, 275, 457, 1017, …
## $ average_syl  &lt;dbl&gt; 1.1698113, 1.1645299, 1.0990566, 1.4931507, 0.8772504, 0…
## $ mlu_words    &lt;dbl&gt; 2.938, 5.839, 2.909, 2.878, 5.674, 4.422, 4.656, 4.070, …
## $ verb_utt     &lt;dbl&gt; 0.500, 1.000, 0.851, 0.189, 0.887, 0.953, 0.673, 0.617, …
## $ dss          &lt;dbl&gt; 8.41, 6.56, 4.96, 6.20, 9.02, 10.24, 9.80, 12.94, 4.89, …
## $ ipsyn_total  &lt;int&gt; 45, 77, 56, 58, 94, 55, 67, 41, 46, 79, 86, 60, 80, 99, …
## $ word_errors  &lt;int&gt; 0, 1, 0, 0, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0,…
## $ total_error  &lt;int&gt; 5, 25, 8, 18, 12, 6, 11, 5, 6, 8, 29, 9, 13, 30, 29, 3, …</code></pre>
<p>The join that I ended up using for this dataset was inner_join(). This join is one that will drop off any NA’s that appear once you join the datasets together. I only wanted to keep the observations that had values for each of the variables (aka, only the children who’d been tested with all of the measures, not just some of them) because I wanted to have as much information as possible for each of my observations. Dropping observations could be problematic because it can limit the sample size of your data, but becauseI had a decent number of observations I felt safe going with inner_join() despite the fact that I may have lost some observations. For this reason, I ended up using inner_join(). Surprisingly, I didn’t have any dropped observations at all–this means that all 1,045 of the children studied in this dataset had been tested for each of the measures presented as variables. If there had been any children that didn’t have a value for, repetition, for example, they would’ve been dropped since I chose to use an inner_join(). My data was also already tidy, so I ended up not having to use pivot_wider or pivot_longer at this stage!</p>
<hr />
</div>
<div id="wrangling" class="section level2">
<h2>Wrangling</h2>
<pre class="r"><code>joineddata %&gt;% filter(group == &quot;SLI&quot;) %&gt;% arrange(total_error)</code></pre>
<pre><code>##    ID    sex age_years corpus group child_TNW child_TNS examiner_TNW freq_ttr
## 1  16 female  5.333333   ENNI   SLI       186        58            4    0.368
## 2  50   male  7.750000   ENNI   SLI       348        54            7    0.273
## 3   1   male  4.916667   ENNI   SLI       212        66           14    0.412
## 4   8   male  4.666667   ENNI   SLI       261        62           38    0.269
##    r_2_i_verbs mor_words num_pos_tags n_dos repetition retracing fillers
## 1    0.7333333       144           23     0         33         0      25
## 2    0.5714286       322           34     1         13         3       3
## 3    5.1428571       194           25     0          7         3       1
## 4    0.1842105       245           24     0          1         8       1
##     s_1g_ppl total_syl average_syl mlu_words verb_utt   dss ipsyn_total
## 1    22.1066       186   1.0000000     2.537    0.175  5.00          33
## 2    61.3748       370   1.0632184     6.224    1.113  9.23          69
## 3    18.2102       248   1.1698113     2.938    0.500  8.41          45
## 4   413.0000       239   0.9157088     4.070    0.617 12.94          41
##    word_errors total_error
## 1            0           3
## 2            0           4
## 3            0           5
## 4            0           5
##  [ reached getOption(&quot;max.print&quot;) -- omitted 73 rows ]</code></pre>
<pre class="r"><code>joineddata %&gt;% filter(group == &quot;TD&quot;) %&gt;% arrange(total_error)</code></pre>
<pre><code>##      ID    sex age_years corpus group child_TNW child_TNS examiner_TNW freq_ttr
## 1   121 female  4.666667   ENNI    TD       330        58            0    0.246
## 2   223 female  6.583333   ENNI    TD       310        64            0    0.331
## 3   132   male  5.166667   ENNI    TD       461        62           18    0.246
## 4   162 female  5.333333   ENNI    TD       396        52            0    0.290
##     r_2_i_verbs mor_words num_pos_tags n_dos repetition retracing fillers
## 1    0.32142857       305           31     0         17         4      11
## 2    0.26315789       296           30     0          4         5       0
## 3    0.27906977       402           38     0         36         2       5
## 4    0.25531915       386           31     0          5         2       1
##      s_1g_ppl total_syl average_syl mlu_words verb_utt   dss ipsyn_total
## 1     22.2075       331   1.0030303     5.259    1.051 12.23          59
## 2     19.6690       338   1.0903226     4.625    1.094  7.66          64
## 3     20.5553       469   1.0173536     6.435    1.194 11.76          67
## 4     21.3389       470   1.1868687     7.385    1.404 10.14          81
##     word_errors total_error
## 1             2           1
## 2             0           1
## 3             0           2
## 4             0           2
##  [ reached getOption(&quot;max.print&quot;) -- omitted 144 rows ]</code></pre>
<pre class="r"><code>joineddata %&gt;% filter(group == &quot;SLI&quot;) %&gt;% arrange(dss)</code></pre>
<pre><code>##    ID    sex age_years corpus group child_TNW child_TNS examiner_TNW freq_ttr
## 1   9   male  4.500000   ENNI   SLI       227        58           93    0.245
## 2  59   male  8.916667   ENNI   SLI       375        60            0    0.304
## 3   3 female  4.666667   ENNI   SLI       212        67            8    0.369
## 4  16 female  5.333333   ENNI   SLI       186        58            4    0.368
##    r_2_i_verbs mor_words num_pos_tags n_dos repetition retracing fillers
## 1    0.3846154       216           23     0          3         1       3
## 2    0.4186047       312           32     1         19        17       7
## 3    0.6000000       195           31     3         13         3       3
## 4    0.7333333       144           23     0         33         0      25
##     s_1g_ppl total_syl average_syl mlu_words verb_utt   dss ipsyn_total
## 1    17.2469       275   1.2114537     3.833    0.875  4.89          46
## 2    17.4394       473   1.2613333     5.183    1.000  4.91          70
## 3    28.4306       233   1.0990566     2.909    0.851  4.96          56
## 4    22.1066       186   1.0000000     2.537    0.175  5.00          33
##    word_errors total_error
## 1            4           6
## 2            0          21
## 3            0           8
## 4            0           3
##  [ reached getOption(&quot;max.print&quot;) -- omitted 73 rows ]</code></pre>
<pre class="r"><code>joineddata %&gt;% filter(group == &quot;TD&quot;) %&gt;% arrange(dss)</code></pre>
<pre><code>##      ID    sex age_years corpus group child_TNW child_TNS examiner_TNW freq_ttr
## 1   202 female  6.500000   ENNI    TD       456        73           17    0.263
## 2   110 female  4.000000   ENNI    TD       261        61            0    0.163
## 3   195   male  6.583333   ENNI    TD       403        59           16    0.256
## 4   176   male  5.333333   ENNI    TD       383        62            2    0.203
##     r_2_i_verbs mor_words num_pos_tags n_dos repetition retracing fillers
## 1    0.25000000       430           36     2          9         6       1
## 2    0.00000000       246           19     0          8         3       6
## 3    0.33333333       348           32     0         17         9       4
## 4    2.12500000       364           27     0          7         8       3
##      s_1g_ppl total_syl average_syl mlu_words verb_utt   dss ipsyn_total
## 1     19.9908       539   1.1820175     5.890    0.973  4.76          78
## 2     22.1657       435   1.6666667     4.017    0.115  5.29          44
## 3     20.0998       467   1.1588089     5.847    1.186  5.34          75
## 4     16.1751       429   1.1201044     5.871    0.355  5.75          52
##     word_errors total_error
## 1             0          39
## 2             1          18
## 3             0          14
## 4             0           7
##  [ reached getOption(&quot;max.print&quot;) -- omitted 144 rows ]</code></pre>
<pre class="r"><code>joineddata %&gt;% mutate(TNW_ratio = child_TNW/examiner_TNW)</code></pre>
<pre><code>##      ID    sex age_years corpus group child_TNW child_TNS examiner_TNW freq_ttr
## 1     1   male  4.916667   ENNI   SLI       212        66           14    0.412
## 2     2   male  5.000000   ENNI   SLI       468        67            2    0.239
## 3     3 female  4.666667   ENNI   SLI       212        67            8    0.369
##     r_2_i_verbs mor_words num_pos_tags n_dos repetition retracing fillers
## 1    5.14285714       194           25     0          7         3       1
## 2    1.36666667       385           34     1         47        10       9
## 3    0.60000000       195           31     3         13         3       3
##      s_1g_ppl total_syl average_syl mlu_words verb_utt   dss ipsyn_total
## 1     18.2102       248   1.1698113     2.938    0.500  8.41          45
## 2     21.1808       545   1.1645299     5.839    1.000  6.56          77
## 3     28.4306       233   1.0990566     2.909    0.851  4.96          56
##     word_errors total_error  TNW_ratio
## 1             0           5  15.142857
## 2             1          25 234.000000
## 3             0           8  26.500000
##  [ reached getOption(&quot;max.print&quot;) -- omitted 222 rows ]</code></pre>
<pre class="r"><code>averages &lt;- joineddata %&gt;% summarize_if(is.numeric, mean, na.rm = T)
sds &lt;- joineddata %&gt;% summarize_if(is.numeric, sd, na.rm = T)
mins &lt;- joineddata %&gt;% summarize_if(is.numeric, min, na.rm = T)
maxs &lt;- joineddata %&gt;% summarize_if(is.numeric, max, na.rm = T)

as.data.frame(averages)</code></pre>
<pre><code>##    ID age_years child_TNW child_TNS examiner_TNW  freq_ttr r_2_i_verbs
## 1 113  6.064074  568.3911     77.28     11.55111 0.2622578   0.4823653
##   mor_words num_pos_tags    n_dos repetition retracing  fillers s_1g_ppl
## 1  504.6311     38.41333 1.453333   20.52889  14.33778 6.795556 83.21245
##   total_syl average_syl mlu_words verb_utt      dss ipsyn_total word_errors
## 1  643.4444    1.130778  6.475062 1.161613 10.56716        82.8   0.4133333
##   total_error
## 1    17.70667</code></pre>
<pre class="r"><code>averages_long &lt;- averages %&gt;% pivot_longer(c(&quot;age_years&quot;, &quot;child_TNW&quot;, 
    &quot;child_TNS&quot;, &quot;examiner_TNW&quot;, &quot;freq_ttr&quot;, &quot;r_2_i_verbs&quot;, &quot;mor_words&quot;, 
    &quot;num_pos_tags&quot;, &quot;n_dos&quot;, &quot;repetition&quot;, &quot;retracing&quot;, &quot;fillers&quot;, 
    &quot;s_1g_ppl&quot;, &quot;total_syl&quot;, &quot;average_syl&quot;, &quot;mlu_words&quot;, &quot;verb_utt&quot;, 
    &quot;dss&quot;, &quot;ipsyn_total&quot;, &quot;word_errors&quot;, &quot;total_error&quot;), names_to = &quot;variable&quot;, 
    values_to = &quot;avg_values&quot;)

as.data.frame(sds)</code></pre>
<pre><code>##         ID age_years child_TNW child_TNS examiner_TNW   freq_ttr r_2_i_verbs
## 1 65.09608  1.411229  226.9658   24.4673      31.5259 0.04684402   0.4986663
##   mor_words num_pos_tags    n_dos repetition retracing  fillers s_1g_ppl
## 1   198.157     6.091768 2.185341    21.1715  11.70209 8.873766 468.6246
##   total_syl average_syl mlu_words  verb_utt      dss ipsyn_total word_errors
## 1  263.7345   0.1075357   1.19928 0.2266473 2.424414    12.48285   0.9223417
##   total_error
## 1    10.05934</code></pre>
<pre class="r"><code>sds_long &lt;- sds %&gt;% pivot_longer(c(&quot;age_years&quot;, &quot;child_TNW&quot;, 
    &quot;child_TNS&quot;, &quot;examiner_TNW&quot;, &quot;freq_ttr&quot;, &quot;r_2_i_verbs&quot;, &quot;mor_words&quot;, 
    &quot;num_pos_tags&quot;, &quot;n_dos&quot;, &quot;repetition&quot;, &quot;retracing&quot;, &quot;fillers&quot;, 
    &quot;s_1g_ppl&quot;, &quot;total_syl&quot;, &quot;average_syl&quot;, &quot;mlu_words&quot;, &quot;verb_utt&quot;, 
    &quot;dss&quot;, &quot;ipsyn_total&quot;, &quot;word_errors&quot;, &quot;total_error&quot;), names_to = &quot;variable&quot;, 
    values_to = &quot;sd_values&quot;)


as.data.frame(mins)</code></pre>
<pre><code>##   ID age_years child_TNW child_TNS examiner_TNW freq_ttr r_2_i_verbs mor_words
## 1  1         4       186        46            0     0.15           0       144
##   num_pos_tags n_dos repetition retracing fillers s_1g_ppl total_syl
## 1           19     0          0         0       0  16.1751       186
##   average_syl mlu_words verb_utt  dss ipsyn_total word_errors total_error
## 1   0.8506944     2.537    0.115 4.76          33           0           1</code></pre>
<pre class="r"><code>mins_long &lt;- mins %&gt;% pivot_longer(c(&quot;age_years&quot;, &quot;child_TNW&quot;, 
    &quot;child_TNS&quot;, &quot;examiner_TNW&quot;, &quot;freq_ttr&quot;, &quot;r_2_i_verbs&quot;, &quot;mor_words&quot;, 
    &quot;num_pos_tags&quot;, &quot;n_dos&quot;, &quot;repetition&quot;, &quot;retracing&quot;, &quot;fillers&quot;, 
    &quot;s_1g_ppl&quot;, &quot;total_syl&quot;, &quot;average_syl&quot;, &quot;mlu_words&quot;, &quot;verb_utt&quot;, 
    &quot;dss&quot;, &quot;ipsyn_total&quot;, &quot;word_errors&quot;, &quot;total_error&quot;), names_to = &quot;variable&quot;, 
    values_to = &quot;min_values&quot;)

as.data.frame(maxs)</code></pre>
<pre><code>##    ID age_years child_TNW child_TNS examiner_TNW freq_ttr r_2_i_verbs mor_words
## 1 225  9.833333      1668       189          315    0.412    5.142857      1570
##   num_pos_tags n_dos repetition retracing fillers s_1g_ppl total_syl
## 1           62    12        230        82      58  6405.61      1783
##   average_syl mlu_words verb_utt   dss ipsyn_total word_errors total_error
## 1    1.666667       9.4    1.671 15.68         105           5          59</code></pre>
<pre class="r"><code>maxs_long &lt;- mins %&gt;% pivot_longer(c(&quot;age_years&quot;, &quot;child_TNW&quot;, 
    &quot;child_TNS&quot;, &quot;examiner_TNW&quot;, &quot;freq_ttr&quot;, &quot;r_2_i_verbs&quot;, &quot;mor_words&quot;, 
    &quot;num_pos_tags&quot;, &quot;n_dos&quot;, &quot;repetition&quot;, &quot;retracing&quot;, &quot;fillers&quot;, 
    &quot;s_1g_ppl&quot;, &quot;total_syl&quot;, &quot;average_syl&quot;, &quot;mlu_words&quot;, &quot;verb_utt&quot;, 
    &quot;dss&quot;, &quot;ipsyn_total&quot;, &quot;word_errors&quot;, &quot;total_error&quot;), names_to = &quot;variable&quot;, 
    values_to = &quot;max_values&quot;)

averages_long %&gt;% full_join(sds_long, by = &quot;variable&quot;) %&gt;% full_join(mins_long, 
    by = &quot;variable&quot;) %&gt;% full_join(maxs_long, by = &quot;variable&quot;) %&gt;% 
    select(variable, avg_values, sd_values, min_values, max_values)</code></pre>
<pre><code>## # A tibble: 21 x 5
##    variable     avg_values sd_values min_values max_values
##    &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 age_years         6.06     1.41         4          4   
##  2 child_TNW       568.     227.         186        186   
##  3 child_TNS        77.3     24.5         46         46   
##  4 examiner_TNW     11.6     31.5          0          0   
##  5 freq_ttr          0.262    0.0468       0.15       0.15
##  6 r_2_i_verbs       0.482    0.499        0          0   
##  7 mor_words       505.     198.         144        144   
##  8 num_pos_tags     38.4      6.09        19         19   
##  9 n_dos             1.45     2.19         0          0   
## 10 repetition       20.5     21.2          0          0   
## # … with 11 more rows</code></pre>
<p>In creating some overall summary statistics (not grouped_by anything) I used pivot_longer to make the table a little easier to read. There were quite a few numeric variables in my dataset, and having all of the summary stats (mean, median, sd, etc) all separate was a bit hard to read. I ended up using pivot_longer on each of the results of my general summary statistics to get a column called “variable” which was just the measure (child_TNW, repetition, fillers, dss, etc) and once I had done that for each of my general summary statistics, I joined them all together to create an easy to read table that had all of my summary statistics in one place.</p>
<pre class="r"><code># summarize by group

joineddata %&gt;% group_by(group) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 2 x 10
##   group avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 SLI            568.          81.4            15.7            25.1
## 2 TD             569.          75.1             9.38           18.1
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<pre class="r"><code>joineddata %&gt;% group_by(sex) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 2 x 10
##   sex   avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 fema…          586.          77.7             8.42           19.9
## 2 male           554.          77.0            14.1            21.0
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<pre class="r"><code>joineddata %&gt;% group_by(corpus) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 1 x 10
##   corpus avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt;          &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 ENNI            568.          77.3             11.6           20.5
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<pre class="r"><code>joineddata %&gt;% group_by(group, sex) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 4 x 11
## # Groups:   group [2]
##   group sex   avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt; &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 SLI   fema…          612.          81.8             9.76           25.7
## 2 SLI   male           541.          81.1            19.3            24.8
## 3 TD    fema…          575.          76.0             7.89           17.6
## 4 TD    male           562.          74.3            10.8            18.6
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<pre class="r"><code>joineddata %&gt;% group_by(group, corpus) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 2 x 11
## # Groups:   group [2]
##   group corpus avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt; &lt;fct&gt;          &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 SLI   ENNI            568.          81.4            15.7            25.1
## 2 TD    ENNI            569.          75.1             9.38           18.1
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<pre class="r"><code>joineddata %&gt;% group_by(sex, corpus) %&gt;% summarize(avg_child_TNW = mean(child_TNW), 
    avg_child_TNS = mean(child_TNS), avg_examiner_TNW = mean(examiner_TNW), 
    avg_repitition = mean(repetition), avg_retracing = mean(retracing), 
    avg_fillers = mean(fillers), avg_total_syl = mean(total_syl), 
    avg_dss = mean(dss), avg_word_errors = mean(word_errors))</code></pre>
<pre><code>## # A tibble: 2 x 11
## # Groups:   sex [2]
##   sex   corpus avg_child_TNW avg_child_TNS avg_examiner_TNW avg_repitition
##   &lt;fct&gt; &lt;fct&gt;          &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;
## 1 fema… ENNI            586.          77.7             8.42           19.9
## 2 male  ENNI            554.          77.0            14.1            21.0
## # … with 5 more variables: avg_retracing &lt;dbl&gt;, avg_fillers &lt;dbl&gt;,
## #   avg_total_syl &lt;dbl&gt;, avg_dss &lt;dbl&gt;, avg_word_errors &lt;dbl&gt;</code></pre>
<p>When I made summary statistics based on group, I was surprised to find that the means for my variables between groups (SLI and TD children) were surprisingly similar almost across the board. The numbers didn’t appear too far off to me, and though I couldn’t tell if they were significantly different just by looking at the numbers, it was interesting to me that the numbers really didn’t seem that different between children who had speech language impairments and those didn’t–I would’ve expected to see some pretty different numbers. When I grouped by sex and corpus, I still didn’t see any drastic differences between male and female kids or between the ENNI and Gilman studies. The average values for each of the measurements of specific language impairments didn’t seem to be very good at distinguishing between SLI and TD kids was definitely interesting to me–how did the original creators of this dataset decide which kids were SLI and which were TD, if all of these measures seemed to be giving similar number for both?</p>
<hr />
</div>
<div id="visualizing" class="section level2">
<h2>Visualizing</h2>
<pre class="r"><code>ggplot(data = joineddata, aes(x = age_years, y = examiner_TNW, 
    color = group)) + geom_point() + scale_color_manual(values = c(&quot;#39998D&quot;, 
    &quot;#BFE1D9&quot;)) + scale_y_continuous(lim = c(1, 300), breaks = seq(0, 
    300, 50)) + labs(x = &quot;child&#39;s age&quot;, y = &quot;examiner&#39;s total # of words&quot;) + 
    ggtitle(&quot;Examiner Total Number of Words based on Child&#39;s Age&quot;) + 
    theme_light()</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /> For this plot, I wanted to see if there was any relationship between the child’s age and the number of words the examiner had to say during the test, and if this varied between kids with SLI and TD kids. There are a couple of kids with SLI that had pretty high intervention from their examiners, but on average there’s no real association. Younger kids may have needed slightly more intervention than older kids, but the scatterplot is pretty even throughout.</p>
<pre class="r"><code># plot2

ggplot(data = joineddata, aes(x = group, y = child_TNS)) + geom_bar(aes(fill = group), 
    stat = &quot;summary&quot;, fun.y = &quot;mean&quot;) + geom_errorbar(stat = &quot;summary&quot;, 
    width = 0.65) + scale_fill_manual(values = c(&quot;#39998D&quot;, &quot;#BFE1D9&quot;)) + 
    labs(y = &quot;child&#39;s total number of sentences&quot;) + ggtitle(&quot;Child&#39;s Total Number of Sentences Based on Group&quot;) + 
    theme_light()</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /> For this plot, I decided to look at the average number of sentences spoken by children based on group, because those values looked to be the most different when I was investigating my summary statistics. When I added error bars to the plots and saw that they didn’t overlap, I concluded that there must be a significant difference between these two groups in terms of the child’s total number of sentences. But what was especially interesting about this data is that TD children actually showed significantly higher number of sentences than kids with SLI–this was really surprising because from the original information provided with this dataset, kids with SLI were expected to have a higher number of sentences spoken than TD kids. So the results from this graph essentially proved the opposite of this expectation, which I thought was super surprising! Some possible reasons for this may be that it was just this particular population of kids tested that happened to end up with a higher number of sentences for TD kids than SLI kids, but given that there are 1044 observations in this dataset, I wonder how reasonable that explanation is. Another potential reason may be that measuring the total number of sentences spoken by kids isn’t an accurate predictor of SLI development in children and that the measure itself is inaccurate, which would definitely be something to look into further.</p>
<pre class="r"><code># selecting only some of my many variables to make this
# correlation heatmap!

joineddata %&gt;% select_if(is.numeric) %&gt;% select(age_years, child_TNS, 
    child_TNW, examiner_TNW, fillers, repetition, retracing, 
    total_syl, verb_utt, word_errors, total_error) %&gt;% cor %&gt;% 
    as.data.frame %&gt;% rownames_to_column %&gt;% pivot_longer(-1) %&gt;% 
    ggplot(aes(rowname, name, fill = value)) + geom_tile() + 
    scale_fill_gradient(high = &quot;#39998D&quot;, low = &quot;#BFE1D9&quot;) + 
    geom_text(aes(label = round(value, 2))) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    ggtitle(&quot;Correlation Heatmap&quot;)</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For this final plot, I ended up only using some of the variables for the correlation heatmap because having all 26 variables made the plot a bit hard to read. The correlation heatmap showed some of the strongest correlations between total syllables and the total number of words spoken by the child (which makes logical sense–the more words you speak, the more syllables you’re also speaking), child total number of words and child total number of sentences, and total error and child total number of words. The correlation between age and examiner’s total number of words was weakly negative, which is in line with what I discovered from my scatterplot above.</p>
<hr />
</div>
<div id="cluster-analysis" class="section level2">
<h2>Cluster Analysis</h2>
<pre class="r"><code>library(cluster)
pam_dat &lt;- joineddata %&gt;% select(repetition, total_syl, dss)
sil_width &lt;- vector()
for (i in 3:10) {
    pam_fit &lt;- pam(pam_dat, k = i)
    sil_width[i] &lt;- pam_fit$silinfo$avg.width
}
ggplot() + geom_line(aes(x = 1:10, y = sil_width)) + scale_x_continuous(name = &quot;k&quot;, 
    breaks = 1:10)</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>pam1 &lt;- joineddata %&gt;% select(repetition, total_syl, dss) %&gt;% 
    pam(k = 3)
pam1</code></pre>
<pre><code>## Medoids:
##       ID repetition total_syl   dss
## [1,] 105         11       427 11.48
## [2,] 191         14       600  8.96
## [3,] 139         22       932 11.56
## Clustering vector:
##   [1] 1 2 1 1 2 1 2 1 1 1 3 1 2 3 3 1 2 1 1 1 3 3 1 2 2 1 3 3 2 1 3 1 2 3 2 2 1
##  [38] 2 2 1 3 1 3 1 2 3 1 3 1 1 1 3 2 3 2 3 1 2 1 2 1 3 2 1 2 3 3 1 3 3 3 3 2 3
##  [75] 2 2 2 3 2 2 1 2 2 1 2 1 1 3 3 1 2 2 3 2 2 3 2 3 1 2
##  [ reached getOption(&quot;max.print&quot;) -- omitted 125 entries ]
## Objective function:
##    build     swap 
## 84.95194 83.85149 
## 
## Available components:
##  [1] &quot;medoids&quot;    &quot;id.med&quot;     &quot;clustering&quot; &quot;objective&quot;  &quot;isolation&quot; 
##  [6] &quot;clusinfo&quot;   &quot;silinfo&quot;    &quot;diss&quot;       &quot;call&quot;       &quot;data&quot;</code></pre>
<pre class="r"><code>final &lt;- joineddata %&gt;% mutate(cluster = as.factor(pam1$clustering))
confmat &lt;- final %&gt;% group_by(group) %&gt;% count(cluster) %&gt;% arrange(desc(n)) %&gt;% 
    pivot_wider(names_from = &quot;cluster&quot;, values_from = &quot;n&quot;, values_fill = list(n = 0))
confmat</code></pre>
<pre><code>## # A tibble: 2 x 4
## # Groups:   group [3]
##   group   `2`   `1`   `3`
##   &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 TD       55    54    39
## 2 SLI      24    29    24</code></pre>
<pre class="r"><code>round(sum(diag(as.matrix(confmat[, 2:4])))/sum(confmat[, 2:4]), 
    4)</code></pre>
<pre><code>## [1] 0.3733</code></pre>
<pre class="r"><code>ggplot(final, aes(x = repetition, y = dss, color = cluster)) + 
    geom_point() + scale_x_continuous(lim = c(0, 100)) + ggtitle(&quot;Cluster Scatterplot&quot;)</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(pam1, which = 2)</code></pre>
<p><img src="/project1_files/figure-html/unnamed-chunk-8-3.png" width="672" style="display: block; margin: auto;" /></p>
<p>For my cluster analysis, I decided to use PAM and to cluster by 3 of my numeric variables–repetition, total_syl, and dss. I wanted to choose variables that could represent a variety of characteristics of a given child’s speech pattern. Things like the number of syllables/words spoken, the structure of the child’s sentences and how exactly they speak, and the complexity of their sentences are all different aspects that can influence whether or not they’re classified as having SLI. Once I’d picked my variables, I needed to determine the number of clusters which I did with a silhouette plot. The k value at the highest point for the plot was at 3, so that’s the number of clusters I inputted into my PAM. Plotting the scatterplot based on the clustering from my PAM didn’t yield very exciting results–the data really didn’t look like it was clustered in any significant way, and the assignment of points to clusters seemed to be almost by chance. Computing the average silhouette width yielded a value of 0.55, which technically indicates a reasonable structure, though it was a bit hard to see on the scatterplot. I checked the accuracy as well, since I knew the data ‘should’ have been grouped by the variable ‘group’ into 2 clusters, but returned back a value of 0.4722, which indicated that the clustering wasn’t super accurate in determining SLI kids from TD kids. Also, if anything, I would’ve expected to see two clusters, one for SLI and one for TD, since that’s what all of these variables were aimed at distinguishing between, so for the silhouette width plot to recommend 3 clusters was already not a great sign. It’s interesting that the clustering didn’t yield super significant results and definitely not the results I expected, but that is in line with what I’d discovered from my summary statistics and plots earlier in this report.</p>
<pre><code>## R version 3.4.4 (2018-03-15)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 18.04.4 LTS
## 
## Matrix products: default
## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices utils     datasets  base     
## 
## other attached packages:
##  [1] cluster_2.0.6    forcats_0.4.0    stringr_1.4.0    dplyr_0.8.3     
##  [5] purrr_0.3.3      readr_1.3.1      tidyr_1.0.0.9000 tibble_2.1.3    
##  [9] ggplot2_3.2.1    tidyverse_1.3.0 
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_0.2.5 xfun_0.13        haven_2.2.0      lattice_0.20-35 
##  [5] colorspace_1.4-1 vctrs_0.2.1      generics_0.0.2   htmltools_0.3.6 
##  [9] yaml_2.2.0       utf8_1.1.4       rlang_0.4.2      pillar_1.4.2    
## [13] withr_2.1.2      glue_1.3.1       DBI_1.0.0        dbplyr_1.4.2    
## [17] modelr_0.1.5     readxl_1.3.1     lifecycle_0.1.0  munsell_0.5.0   
## [21] blogdown_0.18    gtable_0.3.0     cellranger_1.1.0 rvest_0.3.5     
## [25] evaluate_0.14    labeling_0.3     knitr_1.28       fansi_0.4.0     
## [29] broom_0.5.2      Rcpp_1.0.2       backports_1.1.4  scales_1.0.0    
## [33] formatR_1.7      jsonlite_1.6     fs_1.3.1         hms_0.5.3       
## [37] digest_0.6.20    stringi_1.4.3    bookdown_0.18    grid_3.4.4      
## [41] cli_1.1.0        tools_3.4.4      magrittr_1.5     lazyeval_0.2.2  
## [45] crayon_1.3.4     pkgconfig_2.0.2  zeallot_0.1.0    xml2_1.2.2      
## [49] reprex_0.3.0     lubridate_1.7.4  rstudioapi_0.10  assertthat_0.2.1
## [53] rmarkdown_2.1    httr_1.4.1       R6_2.4.0         nlme_3.1-131    
## [57] compiler_3.4.4</code></pre>
<pre><code>## [1] &quot;2020-05-14 22:49:31 CDT&quot;</code></pre>
<pre><code>##                                        sysname 
##                                        &quot;Linux&quot; 
##                                        release 
##                            &quot;4.15.0-99-generic&quot; 
##                                        version 
## &quot;#100-Ubuntu SMP Wed Apr 22 20:32:56 UTC 2020&quot; 
##                                       nodename 
##                   &quot;educcomp01.ccbb.utexas.edu&quot; 
##                                        machine 
##                                       &quot;x86_64&quot; 
##                                          login 
##                                      &quot;unknown&quot; 
##                                           user 
##                                      &quot;an26887&quot; 
##                                 effective_user 
##                                      &quot;an26887&quot;</code></pre>
</div>
